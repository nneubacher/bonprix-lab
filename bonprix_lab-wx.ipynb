{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf728435",
   "metadata": {},
   "source": [
    "<div style=\"padding:24px; background-color:#f8f9fa; border:1px solid #dee2e6; border-radius:10px; line-height:1.6; color:#212529;\">\n",
    "    <h1 style=\"margin-top:0; color:#0d6efd;\">üõçÔ∏è Case Study: Bon Prix Personalization Lab</h1>\n",
    "    <hr style=\"border:0; height:1px; background:#dee2e6; margin:16px 0;\">\n",
    "    <p style=\"font-size:1.05em;\">\n",
    "        <b>Die Herausforderung:</b> Kunden im E-Commerce sind von tausenden Rezensionen √ºberfordert.\n",
    "        Ein reines Sterne-Rating bildet individuelle Bed√ºrfnisse nicht ab.\n",
    "    </p>\n",
    "    <ul style=\"margin-left:20px;\">\n",
    "        <li><b>Ziel:</b> Personalisierte KI-Zusammenfassungen pro Kundin</li>\n",
    "        <li><b>Technologie:</b> LLMs, NLP, Python & Gradio</li>\n",
    "        <li><b>Business Value:</b> H√∂here Conversion & weniger Retouren</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c9c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. WERKZEUGKASTEN & SETUP\n",
    "# ==========================================\n",
    "import pandas as pd     # Datenanalyse (Das \"Excel\" von Python)\n",
    "import gradio as gr     # Erstellung der Web-Oberfl√§che\n",
    "import os, json, re     # Datei- und Textverarbeitung\n",
    "import plotly.graph_objects as go  # Interaktive Business-Grafiken\n",
    "from dotenv import load_dotenv\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "\n",
    "# .env Datei laden (Damit wir unsere Keys nicht hardcoden m√ºssen)\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# KONFIGURATION: W√§hle eine der beiden Optionen\n",
    "# ==========================================\n",
    "\n",
    "# OPTION 1: Credentials aus .env Datei (EMPFOHLEN f√ºr Sicherheit)\n",
    "# Stelle sicher, dass deine .env Datei korrekt ausgef√ºllt ist\n",
    "USE_ENV_FILE = False\n",
    "\n",
    "# OPTION 2: Credentials direkt hier eintragen (NUR f√ºr schnelle Tests)\n",
    "# Setze USE_ENV_FILE = False und trage deine Werte unten ein\n",
    "HARDCODED_API_KEY = \"\"  # Dein IBM Cloud API Key\n",
    "HARDCODED_PROJECT_ID = \"\"  # Deine watsonx.ai Project ID\n",
    "HARDCODED_URL = \"https://us-south.ml.cloud.ibm.com\"  # Standard f√ºr alle Studenten\n",
    "\n",
    "\n",
    "# --- WATSONX SETUP MIT FEHLERBEHANDLUNG ---\n",
    "if USE_ENV_FILE:\n",
    "    IAM_API_KEY = os.getenv(\"WATSONX_API_KEY\")\n",
    "    WATSONX_URL = os.getenv(\"WATSONX_URL\", \"https://us-south.ml.cloud.ibm.com\")  # Fallback auf us-south\n",
    "    PROJECT_ID = os.getenv(\"WATSONX_PROJECT_ID\")\n",
    "    \n",
    "    # Validierung der .env Werte\n",
    "    if not IAM_API_KEY or IAM_API_KEY.strip() == \"\":\n",
    "        raise ValueError(\n",
    "            \"‚ùå FEHLER: WATSONX_API_KEY ist nicht gesetzt!\\n\"\n",
    "            \"L√∂sung 1: F√ºlle die .env Datei korrekt aus\\n\"\n",
    "            \"L√∂sung 2: Setze USE_ENV_FILE = False und trage die Werte direkt im Code ein\"\n",
    "        )\n",
    "    if not PROJECT_ID or PROJECT_ID.strip() == \"\":\n",
    "        raise ValueError(\n",
    "            \"‚ùå FEHLER: WATSONX_PROJECT_ID ist nicht gesetzt!\\n\"\n",
    "            \"L√∂sung 1: F√ºlle die .env Datei korrekt aus\\n\"\n",
    "            \"L√∂sung 2: Setze USE_ENV_FILE = False und trage die Werte direkt im Code ein\"\n",
    "        )\n",
    "    print(\"‚úÖ Credentials erfolgreich aus .env geladen\")\n",
    "else:\n",
    "    IAM_API_KEY = HARDCODED_API_KEY\n",
    "    WATSONX_URL = HARDCODED_URL\n",
    "    PROJECT_ID = HARDCODED_PROJECT_ID\n",
    "    \n",
    "    # Validierung der hardcoded Werte\n",
    "    if not IAM_API_KEY or IAM_API_KEY.strip() == \"\":\n",
    "        raise ValueError(\n",
    "            \"‚ùå FEHLER: HARDCODED_API_KEY ist leer!\\n\"\n",
    "            \"Trage deinen IBM Cloud API Key in HARDCODED_API_KEY ein\"\n",
    "        )\n",
    "    if not PROJECT_ID or PROJECT_ID.strip() == \"\":\n",
    "        raise ValueError(\n",
    "            \"‚ùå FEHLER: HARDCODED_PROJECT_ID ist leer!\\n\"\n",
    "            \"Trage deine watsonx.ai Project ID in HARDCODED_PROJECT_ID ein\"\n",
    "        )\n",
    "    print(\"‚úÖ Hardcoded Credentials werden verwendet\")\n",
    "\n",
    "# URL Validierung und Fallback\n",
    "if not WATSONX_URL or WATSONX_URL.strip() == \"\":\n",
    "    WATSONX_URL = \"https://us-south.ml.cloud.ibm.com\"\n",
    "    print(\"‚ö†Ô∏è  Keine URL angegeben, verwende Standard: us-south\")\n",
    "\n",
    "print(f\"üîó Verwende watsonx URL: {WATSONX_URL}\")\n",
    "print(f\"üì¶ Projekt ID: {PROJECT_ID[:8]}...\")\n",
    "\n",
    "\n",
    "# 1. Parameter definieren (Was bedeutet das eigentlich? => https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-model-parameters.html?context=wx)\n",
    "generate_params = {\n",
    "    GenParams.MAX_NEW_TOKENS: 400,\n",
    "    GenParams.DECODING_METHOD: \"greedy\",\n",
    "    GenParams.REPETITION_PENALTY: 1.1\n",
    "}\n",
    "\n",
    "# 2. ModelInference Instanz erstellen\n",
    "try:\n",
    "    model_inference = ModelInference(\n",
    "        model_id=\"ibm/granite-3-3-8b-instruct\",  # Granite 3.0 8B Instruct Modell\n",
    "        params=generate_params,\n",
    "        credentials=Credentials(api_key=IAM_API_KEY, url=WATSONX_URL),\n",
    "        project_id=PROJECT_ID\n",
    "    )\n",
    "    print(\"‚úÖ watsonx.ai ModelInference erfolgreich initialisiert\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå FEHLER beim Initialisieren von watsonx.ai: {e}\")\n",
    "    print(\"\\nM√∂gliche Ursachen:\")\n",
    "    print(\"1. API Key ist ung√ºltig oder abgelaufen\")\n",
    "    print(\"2. Project ID ist falsch\")\n",
    "    print(\"3. Keine Internetverbindung\")\n",
    "    print(\"4. watsonx.ai Service ist nicht verf√ºgbar\")\n",
    "    raise\n",
    "\n",
    "\n",
    "# Dateipfade (Unsere Datenbasis)\n",
    "USER_FILE = 'personalization_users_visible.csv' \n",
    "REVIEWS_FILE = 'reviews_all_users_in_shop.csv'\n",
    "CACHE_FILE = \"bonprix_project_cache.json\"\n",
    "\n",
    "# Cache-Funktionen (Damit wir nicht f√ºr jede Anfrage die KI neu befragen - und bezahlen - m√ºssen)\n",
    "def get_cache():\n",
    "    if not os.path.exists(CACHE_FILE): return {}\n",
    "    try:\n",
    "        with open(CACHE_FILE, \"r\", encoding=\"utf-8\") as f: return json.load(f)\n",
    "    except: return {}\n",
    "\n",
    "def set_cache(key, val):\n",
    "    c = get_cache()\n",
    "    c[key] = val\n",
    "    with open(CACHE_FILE, \"w\", encoding=\"utf-8\") as f: \n",
    "        json.dump(c, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178ef4c0",
   "metadata": {},
   "source": [
    "<div style=\"padding:18px; background-color:#f5f7fa; border-left:4px solid #0d6efd; border-radius:6px; color:#212529;\">\n",
    "    <h3 style=\"margin-top:0;\">üìä Schritt 1: Das ‚ÄûGed√§chtnis‚Äú der KI</h3>\n",
    "    <p>\n",
    "        Bevor die KI beraten kann, muss sie verstehen, <i>mit wem</i> sie spricht.\n",
    "        Daf√ºr kombinieren wir zwei Datenquellen:\n",
    "    </p>\n",
    "    <table style=\"width:100%; border-collapse:collapse; margin-top:10px;\">\n",
    "        <tr>\n",
    "            <td style=\"padding:8px; border:1px solid #dee2e6;\"><b>Kundenprofile</b></td>\n",
    "            <td style=\"padding:8px; border:1px solid #dee2e6;\">Historische Rezensionen & Pr√§ferenzen</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding:8px; border:1px solid #dee2e6;\"><b>Produktrezensionen</b></td>\n",
    "            <td style=\"padding:8px; border:1px solid #dee2e6;\">Aktuelles Feedback anderer Kunden</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c37969",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BonPrixEngine:\n",
    "    def __init__(self):\n",
    "        # 1. Alle Shop-Rezensionen laden\n",
    "        self.reviews = pd.read_csv(REVIEWS_FILE, sep=';')\n",
    "        self.reviews.columns = [c.strip() for c in self.reviews.columns]\n",
    "        \n",
    "        # 2. User-Profile & Historie aufbauen\n",
    "        self.users = {}\n",
    "        if os.path.exists(USER_FILE):\n",
    "            df_u = pd.read_csv(USER_FILE, sep=';')\n",
    "            df_u.columns = [c.strip() for c in df_u.columns]\n",
    "            \n",
    "            for name in df_u['user_name'].unique():\n",
    "                if pd.isna(name): continue\n",
    "                sub = df_u[df_u['user_name'] == name]\n",
    "                \n",
    "                # Wir verkn√ºpfen alle alten Rezensionstexte zu einem \"Profil-String\"\n",
    "                past_reviews = \" | \".join(sub['review_text'].dropna().astype(str).tolist())\n",
    "                \n",
    "                # Einfache statistische Merkmale (z.B. Durchschnittsgr√∂√üe)\n",
    "                sz_raw = sub['size'].mode()[0] if not sub['size'].mode().empty else \"40\"\n",
    "                sz = int(re.search(r'\\d+', str(sz_raw)).group()) if re.search(r'\\d+', str(sz_raw)) else 38\n",
    "                \n",
    "                self.users[name] = {\n",
    "                    \"base_size\": sz,\n",
    "                    \"height\": sub['body_size'].mode()[0] if not sub['body_size'].mode().empty else \"Unbekannt\",\n",
    "                    \"avg_rating\": round(sub['rating'].mean(), 1) if not sub['rating'].empty else \"N/A\",\n",
    "                    \"past_reviews\": past_reviews \n",
    "                }\n",
    "        \n",
    "        # 3. Produktkatalog (Top 20 Produkte f√ºr die Demo)\n",
    "        top_p = self.reviews['product_id'].value_counts().head(20).index.tolist()\n",
    "        self.products = self.reviews[self.reviews['product_id'].isin(top_p)][['product_id', 'short_description']]\\\n",
    "            .drop_duplicates().set_index('product_id')['short_description'].to_dict()\n",
    "\n",
    "engine = BonPrixEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df39ccc",
   "metadata": {},
   "source": [
    "<div style=\"padding:18px; background-color:#f8f9fa; border-left:4px solid #6c757d; border-radius:6px; color:#212529;\">\n",
    "    <h3 style=\"color:#2c3e50; margin-top:0;\">üß† Schritt 2: Prompt Engineering (Relevanz-Steuerung)</h3>\n",
    "    <p>\n",
    "        Hier definieren wir das <b>Business-Briefing</b>. Als Wirtschaftsinformatiker steuern Sie die KI nicht durch starre Programmierung, sondern durch <b>adaptive Instruktionen</b>.\n",
    "    </p>\n",
    "    <blockquote style=\"margin:12px 0; padding-left:12px; border-left:3px solid #adb5bd; color:#495057; font-style:italic;\">\n",
    "        \"Erkenne das Kundenbed√ºrfnis aus der Historie. Wenn die Kundin Passform-Fragen ignoriert, soll die KI das auch tun. Wir liefern Information, keinen Ballast.\"\n",
    "    </blockquote>\n",
    "    <p style=\"font-size:0.95em;\">\n",
    "        <b>Challenge:</b> Wir nutzen die KI hier f√ºr die <i>Interpretation</i> von Nuancen, w√§hrend wir harte Fakten (wie Gr√∂√üenempfehlungen) den spezialisierten Systemen √ºberlassen.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdb9bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_student_prompt(user_name, profile, product_name, current_product_reviews):\n",
    "    \"\"\"\n",
    "    Diese Funktion baut das 'Briefing' f√ºr die KI.\n",
    "    Hier flie√üt das Business-Wissen ein (Worauf soll die KI achten?).\n",
    "    \"\"\"\n",
    "    \n",
    "    user_meta = f\"K√∂rpergr√∂√üe: {profile.get('height')}, √ò-Rating: {profile.get('avg_rating')}\"\n",
    "    \n",
    "    return f\"\"\"\n",
    "    Die Kundin {user_name} ({user_meta}) schaut sich gerade das Produkt \"{product_name}\" an.\n",
    "    \n",
    "    REZENSIONEN ZUM AKTUELLEN PRODUKT:\n",
    "    {current_product_reviews}\n",
    "    \n",
    "    HISTORIE DER KUNDIN (IHRE ALTEN REZENSIONEN):\n",
    "    \"{profile['past_reviews']}\"\n",
    "    \n",
    "    AUFGABE:\n",
    "    Erstelle eine personalisierte Zusammenfassung der Rezensionen zum neuen Produkt f√ºr {user_name}.\n",
    "    \n",
    "    INSTRUKTIONEN:\n",
    "    1. ANALYSE: Welche Aspekte (z.B. Material, Stil, Nachhaltigkeit) sind f√ºr diese spezifische Kundin \n",
    "       laut ihren alten Rezensionen von Bedeutung?\n",
    "    2. PERSONALISIERUNG: Fasse die neuen Rezensionen NUR im Hinblick auf diese pers√∂nlichen Priorit√§ten zusammen.\n",
    "    3. PASSFORM-VETO: Gehe NUR auf die Passform ein, wenn die Kundin diesen Punkt in ihrer \n",
    "       Vergangenheit selbst erw√§hnt hat.\n",
    "    4. KONTEXT: Ber√ºcksichtige Angaben anderer Kundinnen (z.B. \"f√§llt lang aus\") nur, wenn sie \n",
    "       im Hinblick auf die Metadaten der Kundin ({user_meta}) relevant sind.\n",
    "    \n",
    "    WICHTIG: Max. 4 S√§tze, ehrlich, direkt, Deutsch.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eab15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. ANALYSE-LOGIK (Berechnungen & KI-Aufruf)\n",
    "# ==========================================\n",
    "\n",
    "def run_analysis(user_name, product_selection):\n",
    "    if not user_name or not product_selection: \n",
    "        return [None]*3 + [\"### ‚ö†Ô∏è Bitte links Kundin und Produkt w√§hlen!\", \"\"]\n",
    "    \n",
    "    pid = int(product_selection.split(' - ')[0])\n",
    "    product_name = engine.products.get(pid, \"Unbekanntes Produkt\")\n",
    "    profile = engine.users[user_name]\n",
    "    df = engine.reviews[engine.reviews['product_id'] == pid]\n",
    "    \n",
    "    # --- A. VISUALISIERUNG: Passform & Aspekte ---\n",
    "    txt_all = \" \".join(df['review_text'].dropna().astype(str).tolist()).lower()\n",
    "    \n",
    "    # Passform-Tacho\n",
    "    s, l = len(re.findall(r'klein|eng|kurz', txt_all)), len(re.findall(r'gro√ü|weit|lang', txt_all))\n",
    "    fit_score = (l - s) / (l + s + 1)\n",
    "    fig_gauge = go.Figure(go.Indicator(mode=\"gauge+number\", value=fit_score, title={'text': \"Passform-Tendenz\"},\n",
    "                                       gauge={'axis': {'range': [-1, 1]}, 'bar': {'color': \"#c5003d\"}}))\n",
    "    \n",
    "    # Radar-Chart f√ºr Produkt-Eigenschaften\n",
    "    def get_s(kw): return min(100, int((sum(txt_all.count(w) for w in kw) / (len(df)+1)) * 300))\n",
    "    aspects = {\"Komfort\": get_s([\"bequem\", \"weich\"]), \"Qualit√§t\": get_s([\"qualit√§t\", \"stoff\"]), \n",
    "               \"Stil\": get_s([\"sch√∂n\", \"optik\"]), \"Preis\": get_s([\"preis\", \"g√ºnstig\"])}\n",
    "    fig_radar = go.Figure(data=go.Scatterpolar(r=list(aspects.values()), theta=list(aspects.keys()), fill='toself'))\n",
    "    \n",
    "    # Sterne-Verteilung\n",
    "    counts = df['rating'].value_counts().sort_index()\n",
    "    fig_stars = go.Figure(data=[go.Bar(x=[f\"{i}‚òÖ\" for i in counts.index], y=counts.values, marker_color='#f1c40f')])\n",
    "\n",
    "    for f in [fig_gauge, fig_radar, fig_stars]: \n",
    "        f.update_layout(height=280, margin=dict(l=40, r=40, t=40, b=40), template=\"plotly_white\")\n",
    "\n",
    "    # --- B. KI-PERSONALISIERUNG ---\n",
    "    reviews_sample = \"\\n- \".join(df['review_text'].head(15).astype(str).tolist())[:1500]\n",
    "    final_prompt = build_student_prompt(user_name, profile, product_name, reviews_sample)\n",
    "    \n",
    "    cache = get_cache()\n",
    "    if f\"{user_name}_{pid}\" in cache:\n",
    "        return fig_gauge, fig_radar, fig_stars, cache[f\"{user_name}_{pid}\"], final_prompt\n",
    "    else:\n",
    "        try:\n",
    "            generated_text = model_inference.generate_text(prompt=final_prompt)\n",
    "\n",
    "            set_cache(f\"{user_name}_{pid}\", generated_text)\n",
    "            \n",
    "        except Exception as e:\n",
    "            generated_text = f\"### ‚ö†Ô∏è KI-Fehler\\nWatsonX ist nicht gestartet: {e}\"\n",
    "    \n",
    "    return fig_gauge, fig_radar, fig_stars, generated_text, final_prompt\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033065db",
   "metadata": {},
   "source": [
    "<div style=\"padding:18px; background-color:#f5f7fa; border-left:4px solid #198754; border-radius:6px; color:#212529;\">\n",
    "    <h3 style=\"margin-top:0;\">üöÄ Schritt 3: Das MVP (Minimum Viable Product)</h3>\n",
    "    <p>\n",
    "        Ein Algorithmus ohne Interface ist f√ºr den Fachbereich nicht nutzbar.\n",
    "        Mit <b>Gradio</b> bauen wir eine Web-Oberfl√§che, die den Business-Mehrwert sichtbar macht.\n",
    "    </p>\n",
    "    <p><b>Starten Sie unten das Labor, um das MVP live zu testen.</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d5e10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI DESIGN\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# üõçÔ∏è Bon Prix: Personalization Lab\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1, variant=\"panel\"):\n",
    "            gr.Markdown(\"### üõ†Ô∏è Konfiguration\")\n",
    "            user_dd = gr.Dropdown(choices=list(engine.users.keys()), value=list(engine.users.keys())[0] if engine.users else None, label=\"1. Kundin w√§hlen\")\n",
    "            prod_dd = gr.Dropdown(choices=[f\"{k} - {v}\" for k,v in engine.products.items()], label=\"2. Produkt w√§hlen\")\n",
    "            btn = gr.Button(\"üöÄ Personalisierte Analyse\", variant=\"primary\")\n",
    "            gr.Markdown(\"---\")\n",
    "            gr.Markdown(\"**Info:** Die KI analysiert im Hintergrund die Profile von echten bon prix Kundinnen.\")\n",
    "\n",
    "        with gr.Column(scale=2):\n",
    "            with gr.Tabs():\n",
    "                with gr.TabItem(\"üìù KI-Beratung\"):\n",
    "                    ai_out = gr.Markdown(\"### üí° Ergebnis\\nW√§hlen Sie links eine Kundin und ein Produkt...\")\n",
    "                    with gr.Accordion(\"üîç Prompt-Einsicht (Technik)\", open=False):\n",
    "                        prompt_out = gr.Code(language=\"markdown\")\n",
    "                \n",
    "                with gr.TabItem(\"üìä Statistiken\"):\n",
    "                    with gr.Row():\n",
    "                        plot_gauge = gr.Plot()\n",
    "                        plot_radar = gr.Plot()\n",
    "                    plot_stars = gr.Plot()\n",
    "\n",
    "    btn.click(run_analysis, inputs=[user_dd, prod_dd], outputs=[plot_gauge, plot_radar, plot_stars, ai_out, prompt_out])\n",
    "\n",
    "# Start der App\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(theme=gr.themes.Soft())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
