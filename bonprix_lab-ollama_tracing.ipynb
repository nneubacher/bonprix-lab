{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf728435",
   "metadata": {},
   "source": [
    "<div style=\"padding:25px; background-color:#f8f9fa; border:1px solid #dee2e6; border-radius:10px; line-height:1.6;\">\n",
    "    <h1 style=\"color:#c5003d; margin-top:0;\">üõçÔ∏è Case Study: Bon Prix Personalization Lab</h1>\n",
    "    <hr style=\"border:0; height:1px; background:#dee2e6;\">\n",
    "    <p style=\"font-size:1.1em;\">\n",
    "        <b>Die Herausforderung:</b> Kunden im E-Commerce sind von tausenden Rezensionen √ºberfordert. \n",
    "        Ein Standard-Rating (Sterne) sagt nichts √ºber die individuellen Bed√ºrfnisse aus.\n",
    "    </p>\n",
    "    <ul style=\"margin-left:20px;\">\n",
    "        <li><b>Ziel:</b> KI-gest√ºtzte Zusammenfassungen, die nur das anzeigen, was f√ºr die <i>spezifische</i> Kundin wichtig ist.</li>\n",
    "        <li><b>Technologie:</b> Large Language Models (LLM), NLP, Python & Gradio.</li>\n",
    "        <li><b>Business-Value:</b> H√∂here Conversion-Rate & weniger Retouren durch bessere Passform-Informationen.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c9c16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niko/Dev/IBM/2025/bonprix/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. WERKZEUGKASTEN & SETUP\n",
    "# ==========================================\n",
    "import pandas as pd     # Datenanalyse (Das \"Excel\" von Python)\n",
    "import gradio as gr     # Erstellung der Web-Oberfl√§che\n",
    "import ollama           # Schnittstelle zum lokalen Sprachmodell (Llama 3)\n",
    "import os, json, re     # Datei- und Textverarbeitung\n",
    "import plotly.graph_objects as go  # Interaktive Business-Grafiken\n",
    "from dotenv import load_dotenv\n",
    "from langfuse import observe, get_client\n",
    "\n",
    "\n",
    "# .env Datei laden (Damit wir unsere Keys nicht hardcoden m√ºssen)\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Langfuse Credentials\n",
    "LANGFUSE_PUBLIC_KEY = os.getenv(\"LANGFUSE_PUBLIC_KEY\")\n",
    "LANGFUSE_SECRET_KEY = os.getenv(\"LANGFUSE_SECRET_KEY\")\n",
    "LANGFUSE_BASE_URL = os.getenv(\"LANGFUSE_BASE_URL\")\n",
    "\n",
    "\n",
    "# Dateipfade (Unsere Datenbasis)\n",
    "USER_FILE = 'personalization_users_visible.csv' \n",
    "REVIEWS_FILE = 'reviews_all_users_in_shop.csv'\n",
    "CACHE_FILE = \"bonprix_project_cache.json\"\n",
    "\n",
    "# Cache-Funktionen (Damit wir nicht f√ºr jede Anfrage die KI neu bezahlen/befragen m√ºssen)\n",
    "def get_cache():\n",
    "    if not os.path.exists(CACHE_FILE): return {}\n",
    "    try:\n",
    "        with open(CACHE_FILE, \"r\", encoding=\"utf-8\") as f: return json.load(f)\n",
    "    except: return {}\n",
    "\n",
    "def set_cache(key, val):\n",
    "    c = get_cache()\n",
    "    c[key] = val\n",
    "    with open(CACHE_FILE, \"w\", encoding=\"utf-8\") as f: \n",
    "        json.dump(c, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178ef4c0",
   "metadata": {},
   "source": [
    "<div style=\"padding:15px; background-color:#e3f2fd; border-left:5px solid #2196f3; border-radius:5px;\">\n",
    "    <h3 style=\"color:#0d47a1; margin-top:0;\">üìä Schritt 1: Das \"Ged√§chtnis\" f√ºttern</h3>\n",
    "    <p>Bevor die KI beraten kann, muss sie wissen, mit wem sie spricht. Wir kombinieren zwei Datenquellen:</p>\n",
    "    <table style=\"width:100%; border-collapse: collapse; margin-top:10px;\">\n",
    "        <tr style=\"background-color:rgba(255,255,255,0.5);\">\n",
    "            <td style=\"padding:8px; border:1px solid #bbdefb;\"><b>Kunden-Profile</b></td>\n",
    "            <td style=\"padding:8px; border:1px solid #bbdefb;\">Historische Rezensionen: Was hat die Kundin fr√ºher bem√§ngelt oder gelobt?</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding:8px; border:1px solid #bbdefb;\"><b>Produkt-Rezensionen</b></td>\n",
    "            <td style=\"padding:8px; border:1px solid #bbdefb;\">Aktuelles Feedback anderer Kunden zum neuen Wunsch-Produkt.</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71c37969",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BonPrixEngine:\n",
    "    def __init__(self):\n",
    "        # 1. Alle Shop-Rezensionen laden\n",
    "        self.reviews = pd.read_csv(REVIEWS_FILE, sep=';')\n",
    "        self.reviews.columns = [c.strip() for c in self.reviews.columns]\n",
    "        \n",
    "        # 2. User-Profile & Historie aufbauen\n",
    "        self.users = {}\n",
    "        if os.path.exists(USER_FILE):\n",
    "            df_u = pd.read_csv(USER_FILE, sep=';')\n",
    "            df_u.columns = [c.strip() for c in df_u.columns]\n",
    "            \n",
    "            for name in df_u['user_name'].unique():\n",
    "                if pd.isna(name): continue\n",
    "                sub = df_u[df_u['user_name'] == name]\n",
    "                \n",
    "                # Wir verkn√ºpfen alle alten Rezensionstexte zu einem \"Profil-String\"\n",
    "                past_reviews = \" | \".join(sub['review_text'].dropna().astype(str).tolist())\n",
    "                \n",
    "                # Einfache statistische Merkmale (z.B. Durchschnittsgr√∂√üe)\n",
    "                sz_raw = sub['size'].mode()[0] if not sub['size'].mode().empty else \"40\"\n",
    "                sz = int(re.search(r'\\d+', str(sz_raw)).group()) if re.search(r'\\d+', str(sz_raw)) else 38\n",
    "                \n",
    "                self.users[name] = {\n",
    "                    \"base_size\": sz,\n",
    "                    \"past_reviews\": past_reviews # Das \"Ged√§chtnis\" f√ºr die KI\n",
    "                }\n",
    "        \n",
    "        # 3. Produktkatalog (Top 20 Produkte f√ºr die Demo)\n",
    "        top_p = self.reviews['product_id'].value_counts().head(20).index.tolist()\n",
    "        self.products = self.reviews[self.reviews['product_id'].isin(top_p)][['product_id', 'short_description']]\\\n",
    "            .drop_duplicates().set_index('product_id')['short_description'].to_dict()\n",
    "\n",
    "engine = BonPrixEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2df39ccc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character 'üß†' (U+1F9E0) (2241122232.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m<h3 style=\"color:#e65100; margin-top:0;\">üß† Schritt 2: Prompt Engineering (Management via AI)</h3>\u001b[39m\n                                             ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid character 'üß†' (U+1F9E0)\n"
     ]
    }
   ],
   "source": [
    "<div style=\"padding:20px; background-color:#fff3e0; border:2px dashed #ff9800; border-radius:10px;\">\n",
    "    <h3 style=\"color:#e65100; margin-top:0;\">üß† Schritt 2: Prompt Engineering (Management via AI)</h3>\n",
    "    <p>Hier definieren wir das <b>\"Briefing\"</b> f√ºr unser Sprachmodell. Als Manager steuern Sie die KI nicht durch Code, sondern durch pr√§zise Instruktionen:</p>\n",
    "    <blockquote style=\"font-style:italic; color:#5d4037; border-left:3px solid #ffb74d; padding-left:15px;\">\n",
    "        \"Analysiere, welche Aspekte (Material, Stil, Passform) f√ºr diese Kundin laut ihrer Historie wichtig sind und fasse das neue Produkt NUR darauf basierend zusammen.\"\n",
    "    </blockquote>\n",
    "    <p style=\"font-size:0.9em; margin-top:10px;\"><b>Interaktive Aufgabe:</b> Wir werden gleich versuchen, den Tonfall der KI zu √§ndern. Was passiert, wenn wir die KI anweisen, 'extrem kritisch' zu sein?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebdb9bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_student_prompt(user_name, profile, product_name, current_product_reviews):\n",
    "    \"\"\"\n",
    "    Diese Funktion baut das 'Briefing' f√ºr die KI.\n",
    "    Hier flie√üt das Business-Wissen ein (Worauf soll die KI achten?).\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "    Die Kundin {user_name} schaut sich gerade das Produkt \"{product_name}\" an.\n",
    "    \n",
    "    HIER SIND DIE REZENSIONEN ZUM AKTUELLEN PRODUKT:\n",
    "    {current_product_reviews}\n",
    "    \n",
    "    DIE KUNDIN SELBST HAT IN DER VERGANGENHEIT FOLGENDE REZENSIONEN GESCHRIEBEN:\n",
    "    \"{profile['past_reviews']}\"\n",
    "    \n",
    "    AUFGABE:\n",
    "    Erstelle eine personalisierte Zusammenfassung der Rezensionen zum neuen Produkt f√ºr {user_name}.\n",
    "    Analysiere daf√ºr zuerst, welche Aspekte (z.B. Material, Stil, Nachhaltigkeit, Passform) f√ºr {user_name} \n",
    "    laut ihren alten Rezensionen besonders wichtig sind. \n",
    "    Fasse dann die neuen Rezensionen genau im Hinblick auf diese pers√∂nlichen Priorit√§ten zusammen.\n",
    "    \n",
    "    WICHTIG:\n",
    "    - Wenn die Kundin nie √ºber Gr√∂√üe geschrieben hat, ignoriere das Thema Passform.\n",
    "    - Konzentriere dich auf ihre Nuancen.\n",
    "    - Schreibe direkt, ehrlich und in max. 4 S√§tzen auf Deutsch.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eab15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. ANALYSE-LOGIK (Berechnungen & KI-Aufruf)\n",
    "# ==========================================\n",
    "\n",
    "langfuse = get_client()\n",
    "\n",
    "\n",
    "@observe(name=\"BonPrix_Project\", capture_output=False)\n",
    "def run_analysis(user_name, product_selection):\n",
    "    if not user_name or not product_selection: \n",
    "        return [None]*3 + [\"### ‚ö†Ô∏è Bitte links Kundin und Produkt w√§hlen!\", \"\"]\n",
    "    \n",
    "    pid = int(product_selection.split(' - ')[0])\n",
    "    product_name = engine.products.get(pid, \"Unbekanntes Produkt\")\n",
    "    profile = engine.users[user_name]\n",
    "    df = engine.reviews[engine.reviews['product_id'] == pid]\n",
    "    \n",
    "    # Wir loggen Metadaten f√ºr das Management-Dashboard\n",
    "    langfuse.update_current_span(\n",
    "        metadata={\n",
    "            \"customer_name\": user_name,\n",
    "            \"product_id\": pid,\n",
    "            \"past_reviews_count\": len(profile['past_reviews'].split('|'))\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # --- A. VISUALISIERUNG: Passform & Aspekte ---\n",
    "    txt_all = \" \".join(df['review_text'].dropna().astype(str).tolist()).lower()\n",
    "    \n",
    "    # Passform-Tacho\n",
    "    s, l = len(re.findall(r'klein|eng|kurz', txt_all)), len(re.findall(r'gro√ü|weit|lang', txt_all))\n",
    "    fit_score = (l - s) / (l + s + 1)\n",
    "    fig_gauge = go.Figure(go.Indicator(mode=\"gauge+number\", value=fit_score, title={'text': \"Passform-Tendenz\"},\n",
    "                                       gauge={'axis': {'range': [-1, 1]}, 'bar': {'color': \"#c5003d\"}}))\n",
    "    \n",
    "    # Radar-Chart f√ºr Produkt-Eigenschaften\n",
    "    def get_s(kw): return min(100, int((sum(txt_all.count(w) for w in kw) / (len(df)+1)) * 300))\n",
    "    aspects = {\"Komfort\": get_s([\"bequem\", \"weich\"]), \"Qualit√§t\": get_s([\"qualit√§t\", \"stoff\"]), \n",
    "               \"Stil\": get_s([\"sch√∂n\", \"optik\"]), \"Preis\": get_s([\"preis\", \"g√ºnstig\"])}\n",
    "    fig_radar = go.Figure(data=go.Scatterpolar(r=list(aspects.values()), theta=list(aspects.keys()), fill='toself'))\n",
    "    \n",
    "    # Sterne-Verteilung\n",
    "    counts = df['rating'].value_counts().sort_index()\n",
    "    fig_stars = go.Figure(data=[go.Bar(x=[f\"{i}‚òÖ\" for i in counts.index], y=counts.values, marker_color='#f1c40f')])\n",
    "\n",
    "    for f in [fig_gauge, fig_radar, fig_stars]: \n",
    "        f.update_layout(height=280, margin=dict(l=40, r=40, t=40, b=40), template=\"plotly_white\")\n",
    "\n",
    "\n",
    "    # --- B. KI-PERSONALISIERUNG ---\n",
    "    reviews_sample = \"\\n- \".join(df['review_text'].head(15).astype(str).tolist())[:1500]\n",
    "    final_prompt = build_student_prompt(user_name, profile, product_name, reviews_sample)\n",
    "    \n",
    "    cache = get_cache()\n",
    "    if f\"{user_name}_{pid}\" in cache:\n",
    "        return fig_gauge, fig_radar, fig_stars, cache[f\"{user_name}_{pid}\"], final_prompt\n",
    "    else:\n",
    "        try:\n",
    "            ans = \"\"\n",
    "            with langfuse.start_as_current_observation(\n",
    "                name=\"ollama-generation\",\n",
    "                as_type=\"generation\",\n",
    "                model=\"llama3\",\n",
    "                input=final_prompt\n",
    "            ) as generation:\n",
    "                \n",
    "                generated_text = ollama.chat(model=\"llama3\", messages=[{'role': 'user', 'content': final_prompt}])\n",
    "                ans = generated_text['message']['content']\n",
    "                set_cache(f\"{user_name}_{pid}\", ans)\n",
    "\n",
    "                generation.update(\n",
    "                    output=ans,\n",
    "                    metadata={\"engine\": \"ollama\"}\n",
    "                )\n",
    "\n",
    "                langfuse.update_current_trace(output=ans)\n",
    "        except Exception as e:\n",
    "            langfuse.update_current_span(level=\"ERROR\", status_message=str(e))\n",
    "            ans = f\"### ‚ö†Ô∏è KI-Fehler\\nOllama ist nicht gestartet: {e}\"\n",
    "\n",
    "    langfuse.flush()\n",
    "\n",
    "    return fig_gauge, fig_radar, fig_stars, ans, final_prompt\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033065db",
   "metadata": {},
   "source": [
    "<div style=\"padding:15px; background-color:#e8f5e9; border-left:5px solid #4caf50; border-radius:5px;\">\n",
    "    <h3 style=\"color:#1b5e20; margin-top:0;\">üöÄ Schritt 3: Das MVP (Minimum Viable Product)</h3>\n",
    "    <p>Ein Algorithmus ohne Interface ist f√ºr den Fachbereich nutzlos. Mit <b>Gradio</b> bauen wir eine Web-Oberfl√§che, die zeigt, wie die L√∂sung im Kundensupport oder in der App aussehen k√∂nnte.</p>\n",
    "    <b>Klicken Sie unten auf den Link, um das Labor zu starten!</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4d5e10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ts/0dhd43l91q956_87n7js139h0000gn/T/ipykernel_94747/2165335655.py:2: UserWarning: The parameters have been moved from the Blocks constructor to the launch() method in Gradio 6.0: theme. Please pass these parameters to launch() instead.\n",
      "  with gr.Blocks(theme=gr.themes.Soft()) as demo:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# UI DESIGN\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# üõçÔ∏è Bon Prix: Personalization Lab\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1, variant=\"panel\"):\n",
    "            gr.Markdown(\"### üõ†Ô∏è Konfiguration\")\n",
    "            user_dd = gr.Dropdown(choices=list(engine.users.keys()), value=list(engine.users.keys())[0] if engine.users else None, label=\"1. Kundin w√§hlen\")\n",
    "            prod_dd = gr.Dropdown(choices=[f\"{k} - {v}\" for k,v in engine.products.items()], label=\"2. Produkt w√§hlen\")\n",
    "            btn = gr.Button(\"üöÄ Personalisierte Analyse\", variant=\"primary\")\n",
    "            gr.Markdown(\"---\")\n",
    "            gr.Markdown(\"**Info:** Die KI analysiert im Hintergrund die Profile von echten bon prix Kundinnen.\")\n",
    "\n",
    "        with gr.Column(scale=2):\n",
    "            with gr.Tabs():\n",
    "                with gr.TabItem(\"üìù KI-Beratung\"):\n",
    "                    ai_out = gr.Markdown(\"### üí° Ergebnis\\nW√§hlen Sie links eine Kundin und ein Produkt...\")\n",
    "                    with gr.Accordion(\"üîç Prompt-Einsicht (Technik)\", open=False):\n",
    "                        prompt_out = gr.Code(language=\"markdown\")\n",
    "                \n",
    "                with gr.TabItem(\"üìä Statistiken\"):\n",
    "                    with gr.Row():\n",
    "                        plot_gauge = gr.Plot()\n",
    "                        plot_radar = gr.Plot()\n",
    "                    plot_stars = gr.Plot()\n",
    "\n",
    "    btn.click(run_analysis, inputs=[user_dd, prod_dd], outputs=[plot_gauge, plot_radar, plot_stars, ai_out, prompt_out])\n",
    "\n",
    "# Start der App\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f827cad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
